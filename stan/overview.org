#+AUTHOR: Simon Stoltze
#+EMAIL: sstoltze@gmail.com

* Overview
This file is meant as a starting point for writing stan programs and how to use them in combination with org-babel to do literate programming. A guide for most of this can be found at [[https://orgmode.org/worg/org-contrib/babel/languages/ob-doc-stan.html]].

* Simple example
:PROPERTIES:
:header-args: :tangle overview-model.stan
:END:
This is a simple example to demonstrate how everything works. First, write a small stan program:
#+NAME: model-stan
#+BEGIN_SRC stan :file model.stan :results silent
  data {
    int<lower=1> N; // N samples
    vector[N] x;
  }

  parameters {
    real mu;
    real<lower=0> sigma; // sigma is positive
  }

  model {
    x ~ normal(mu, sigma); // We expect the input data to be normally distributed, norm mu and mean sigma
  }

#+END_SRC

The result of evaluating this is a file with the code, found in [[./model.stan]]. This file can then be imported into other source-blocks.
** R
:PROPERTIES:
:header-args: :results output :tangle r-stan.R :session *R-stan*
:END:
#+BEGIN_SRC R :results silent
  set.seed(33)

  N <- 50
  x <- rnorm(N, 20, 3)
#+END_SRC

Note that the following code takes a little while to run.
#+BEGIN_SRC R :var model=model-stan
  library(rstan)
  rstan_options(auto_write = TRUE)

  fit <- stan(file=model, data=list(N=N, x=x), chains=1)
#+END_SRC

#+RESULTS:
#+begin_example

Loading required package: ggplot2
Loading required package: StanHeaders
rstan (Version 2.17.4, GitRev: 2e1f913d3ca3)
For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)

SAMPLING FOR MODEL 'model' NOW (CHAIN 1).

Gradient evaluation took 6e-06 seconds
1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 0.020805 seconds (Warm-up)
               0.01525 seconds (Sampling)
               0.036055 seconds (Total)
#+end_example

#+BEGIN_SRC R
  print(fit)
#+END_SRC

#+RESULTS:
#+begin_example
Inference for Stan model: model.
1 chains, each with iter=2000; warmup=1000; thin=1;
post-warmup draws per chain=1000, total post-warmup draws=1000.

        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
mu     20.52    0.01 0.38  19.76  20.27  20.51  20.77  21.27   723    1
sigma   2.62    0.01 0.28   2.14   2.44   2.59   2.77   3.23   749    1
lp__  -71.35    0.05 1.13 -74.23 -71.71 -70.99 -70.58 -70.32   472    1

Samples were drawn using NUTS(diag_e) at Thu Oct 25 00:36:36 2018.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at
convergence, Rhat=1).
#+end_example

#+BEGIN_SRC R :results graphics :file ./images/example.png
  plot(fit)
#+END_SRC

#+RESULTS:
[[file:./images/example.png]]

After running this, we can see the plot:
[[./images/example.png]]

** Python
:PROPERTIES:
:header-args: :results output :tangle py-stan.py :session *Python*
:END:

To use Python, first we need to import the library. We will also import pandas to generate some random data for testing.
#+BEGIN_SRC python :results silent
import pystan
import pandas as pd
import numpy as np
import scipy as sp
import arviz as az # ??? matplotlib replacement?
import pickle
#+END_SRC

The we generate the testing data:
#+BEGIN_SRC python :results silent
np.random.seed(33)

N = 50
x = np.random.randn(N)
#+END_SRC

Then we can compile the model, which takes a bit of time. To save time, we save the model in a file so we do not have to recalculate it.
#+BEGIN_SRC python :results silent :var model=model-stan
try:
    with open("pickled_model.pickle", "rb") as pickle_file:
        stan_model = pickle.load(pickle_file)
except FileNotFoundError:
    stan_model = pystan.StanModel(file=model)
    with open("pickled_model.pickle", "wb") as pickle_file:
        pickle.dump(stan_model, pickle_file)
#+END_SRC

And then run the code as we did before:

#+BEGIN_SRC python
fit = stan_model.sampling(data={'N': N, 'x' : x}, chains=1)
#+END_SRC

#+RESULTS:
#+begin_example
Gradient evaluation took 1.5e-05 seconds
1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 0.025134 seconds (Warm-up)
               0.020288 seconds (Sampling)
               0.045422 seconds (Total)
#+end_example

To see what happened, we can print the result.
#+BEGIN_SRC python
print(fit)
#+END_SRC

#+RESULTS:
#+begin_example
Inference for Stan model: anon_model_39de6566d10813b7cfe15e72b8d61dd1.
1 chains, each with iter=2000; warmup=1000; thin=1;
post-warmup draws per chain=1000, total post-warmup draws=1000.

        mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat
mu     -0.19  5.5e-3   0.14  -0.48  -0.29  -0.18  -0.09   0.08    666    1.0
sigma   0.99  4.4e-3   0.11    0.8   0.92   0.98   1.06   1.21    607    1.0
lp__   -23.7    0.05   0.97 -26.16 -24.13 -23.44 -22.96 -22.65    451    1.0

Samples were drawn using NUTS at Thu Oct 25 00:35:02 2018.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at
convergence, Rhat=1).
#+end_example

I can't get Arviz to generate any plots, I am probably doing something wrong. The following code generates an array of matplotlib Axes, but I am unable to show them. Possibly arviz/something else requires an IPython notebook. I can still generate plots the old way with 'fit.plot().savefig()'.

#+BEGIN_SRC python :results graphics :file "./images/pygraph.png"
# Arviz, doesn't work at the moment
az.plot_density(fit, var_names=['mu', 'sigma'])
#+END_SRC

#+RESULTS:
[[file:./images/pygraph.png]]

#+BEGIN_SRC python :results silent
# Old fashioned, generates a warning but works
fit.plot().savefig("./images/pygraph-savefig.png")
#+END_SRC

New plot:
[[./images/pygraph.png]]

Old plot:
[[./images/pygraph-savefig.png]]
